## üß± CHECKLIST ‚Äî Testes de Performance e Resili√™ncia em Solu√ß√µes Cloud

### üîπ 1. Prepara√ß√£o do Ambiente

**Objetivo:** Garantir condi√ß√µes controladas e reproduz√≠veis.
**A√ß√µes:**

- [ ] Confirmar ambiente isolado de produ√ß√£o (staging, homolog, performance).
- [ ] Sincronizar vers√µes de c√≥digo, banco e configura√ß√µes com produ√ß√£o.
- [ ] Desativar logs verbosos e tracing detalhado (apenas quando necess√°rio).
- [ ] Configurar ferramentas de observabilidade (Prometheus, Grafana, New Relic, Datadog, CloudWatch).
- [ ] Validar limites de escalabilidade autom√°tica (HPA no Kubernetes, Auto Scaling Groups no AWS, VMSS no Azure).
- [ ] Garantir infraestrutura como c√≥digo (Terraform, CloudFormation, Pulumi) para reprodutibilidade.

**‚ö†Ô∏è Ponto de Aten√ß√£o:**
Erros comuns incluem testar com cache ativo, escalabilidade desligada ou em inst√¢ncias subdimensionadas.

---

### üîπ 2. Defini√ß√£o de Objetivos e Cen√°rios

**Objetivo:** Medir o que realmente importa.
**A√ß√µes:**

- [ ] Definir metas de performance (ex: _p95 latency < 300ms_, _throughput > 2000 req/s_).
- [ ] Mapear fluxos cr√≠ticos do sistema: login, pagamento, consulta de saldo, fechamento de lote, etc.
- [ ] Identificar limites funcionais e t√©cnicos (CPU, mem√≥ria, I/O, rede, conex√µes DB).
- [ ] Selecionar tipo de teste:

  - **Load Test:** capacidade nominal.
  - **Stress Test:** limite m√°ximo antes da falha.
  - **Spike Test:** comportamento sob picos repentinos.
  - **Endurance Test:** estabilidade a longo prazo.
  - **Chaos Test:** resili√™ncia a falhas (injetar erros, desligar servi√ßos).

**‚ö†Ô∏è Ponto de Aten√ß√£o:**
Em sistemas financeiros, simular transa√ß√µes realistas (payloads, volumes, depend√™ncias de API externas).

---

### üîπ 3. Ferramentas de Teste

**Objetivo:** Selecionar stack adequada.
**A√ß√µes:**

- [ ] Ferramentas de carga: **k6**, **JMeter**, **Gatling**, **Locust**.
- [ ] Orquestra√ß√£o: **Grafana k6 Operator**, **AWS Fargate**, **Azure Load Testing**, **Google Cloud Performance Testing**.
- [ ] Chaos Engineering: **Gremlin**, **LitmusChaos**, **Chaos Mesh**, **Azure Chaos Studio**.
- [ ] Testes de APIs: **Postman/Newman**, **Artillery**, **k6 REST/GraphQL scripts**.
- [ ] Monitoramento: **Prometheus + Grafana dashboards customizados**.

**‚ö†Ô∏è Ponto de Aten√ß√£o:**
O teste deve ser automatizado via CI/CD (GitHub Actions, Jenkins, GitLab CI) com thresholds definidos ‚Äî falhas autom√°ticas se violar limites.

---

### üîπ 4. Execu√ß√£o dos Testes

**Objetivo:** Rodar cargas representativas com controle e visibilidade.
**A√ß√µes:**

- [ ] Aumentar gradualmente a carga at√© o limite esperado.
- [ ] Testar sob m√∫ltiplas zonas/regions para lat√™ncia cross-region.
- [ ] Validar autoescalonamento horizontal e vertical.
- [ ] Injetar falhas controladas:

  - Derrubar pods ou servi√ßos aleat√≥rios.
  - Introduzir lat√™ncia artificial (ex: _tc qdisc add delay_).
  - Desabilitar componentes de cache ou mensageria temporariamente.

- [ ] Coletar m√©tricas em tempo real.

**‚ö†Ô∏è Ponto de Aten√ß√£o:**
Monitorar uso de CPU, mem√≥ria, filas, conex√µes de banco e _timeouts_ de downstream APIs.

---

### üîπ 5. M√©tricas de Performance

**Objetivo:** Quantificar efici√™ncia e escalabilidade.
**Principais m√©tricas:**

| Categoria                | M√©trica                         | Meta / Observa√ß√£o                |
| ------------------------ | ------------------------------- | -------------------------------- |
| **Lat√™ncia**             | p50, p95, p99                   | Respostas r√°pidas e consistentes |
| **Throughput**           | req/s ou transa√ß√µes/s           | Avaliar volume processado        |
| **Erro**                 | % de falhas, HTTP 5xx           | Toler√¢ncia ‚â§ 1%                  |
| **Recursos**             | CPU, mem√≥ria, disco, I/O, rede  | Ideal < 80% utiliza√ß√£o           |
| **Tempo de GC**          | Pausas do Garbage Collector     | < 100ms                          |
| **DB performance**       | Tempo m√©dio de query, deadlocks | Avaliar queries lentas           |
| **Escalabilidade**       | Tempo de boot de inst√¢ncia/pod  | < 60s                            |
| **Custo por requisi√ß√£o** | (Custo total √∑ n¬∫ de reqs)      | Avaliar efici√™ncia financeira    |

---

### üîπ 6. M√©tricas de Resili√™ncia

**Objetivo:** Validar capacidade de recupera√ß√£o e continuidade.
**M√©tricas:**

| Tipo                                  | Indicador                          | Meta                      |
| ------------------------------------- | ---------------------------------- | ------------------------- |
| **MTBF** (Mean Time Between Failures) | Intervalo m√©dio entre falhas       | > 24h                     |
| **MTTR** (Mean Time to Recovery)      | Tempo m√©dio de recupera√ß√£o         | < 5min                    |
| **RTO** (Recovery Time Objective)     | Tempo m√°ximo aceit√°vel de parada   | conforme SLA              |
| **RPO** (Recovery Point Objective)    | Dados perdidos aceit√°veis          | 0 em sistemas financeiros |
| **Erro tolerado**                     | Requests degradados mas n√£o falhos | < 2%                      |

---

### üîπ 7. An√°lise dos Resultados

**Objetivo:** Extrair valor e orientar decis√µes.
**A√ß√µes:**

- [ ] Consolidar logs e m√©tricas em dashboards (Grafana, CloudWatch, Datadog).
- [ ] Calcular tempo m√©dio, percentis e variabilidade.
- [ ] Identificar _bottlenecks_ (CPU, DB, rede, locking).
- [ ] Correlacionar incidentes com logs de aplica√ß√£o e tracing (OpenTelemetry, Jaeger).
- [ ] Documentar cada itera√ß√£o: setup, resultados, a√ß√µes corretivas.

**‚ö†Ô∏è Ponto de Aten√ß√£o:**
Evite an√°lises isoladas ‚Äî correlacione lat√™ncia com uso de CPU e tr√°fego de rede.

---

### üîπ 8. A√ß√µes Corretivas

**Objetivo:** Implementar melhorias.
**A√ß√µes:**

- [ ] Revisar _pool sizes_ (threads, conex√µes DB).
- [ ] Otimizar queries SQL e √≠ndices.
- [ ] Implementar caching e compress√£o de payloads.
- [ ] Avaliar filas ass√≠ncronas (Kafka, SQS, Pub/Sub).
- [ ] Configurar circuit breakers e retries (Resilience4j, Spring Cloud).
- [ ] Reduzir _cold starts_ em fun√ß√µes serverless.
- [ ] Validar observabilidade e alertas proativos.

---

### üîπ 9. Teste de Resili√™ncia Avan√ßado (Chaos Engineering)

**Objetivo:** Validar comportamento sob falhas reais.
**A√ß√µes:**

- [ ] Desligar servi√ßos aleat√≥rios (simula√ß√£o de node failure).
- [ ] Cortar comunica√ß√£o entre microservi√ßos.
- [ ] Injetar lentid√£o em endpoints cr√≠ticos.
- [ ] Reiniciar DBs, filas e caches sob carga.
- [ ] Validar observabilidade e _self-healing_.

**M√©tricas observadas:**

- Tempo de recupera√ß√£o.
- Impacto no throughput.
- Percentual de requisi√ß√µes degradadas.
- Consist√™ncia dos dados ap√≥s recupera√ß√£o.

---

### üîπ 10. Relat√≥rio Final e Comunica√ß√£o

**Objetivo:** Formalizar e comunicar os resultados.
**Conte√∫do do relat√≥rio:**

- Objetivo dos testes.
- Ambiente e configura√ß√µes usadas.
- Cen√°rios executados.
- M√©tricas obtidas (tabelas e gr√°ficos).
- _Bottlenecks_ identificados.
- Recomenda√ß√µes e plano de a√ß√£o.
- Riscos e pr√≥ximos passos.

**‚ö†Ô∏è Ponto de Aten√ß√£o:**
Inclua sempre an√°lise custo x benef√≠cio ‚Äî nem sempre o melhor desempenho justifica o custo extra de infraestrutura.

---

## üìä Recomenda√ß√µes Extras (Solu√ß√µes Financeiras em Cloud)

- Ativar **circuit breakers** e **fallbacks** entre microservi√ßos para evitar cascatas de falha.
- Usar **mensageria idempotente** (Kafka, RabbitMQ) para garantir consist√™ncia transacional.
- Criar **testes de rollback** e **reprocessamento de mensagens**.
- Usar **feature flags** para reduzir impacto de deploys em picos.
- Aplicar **rate limiting e throttling** para proteger APIs p√∫blicas.
- Medir **tempo de liquida√ß√£o** (lat√™ncia fim-a-fim entre origem e confirma√ß√£o financeira).
- Auditar **integridade de logs e eventos** (imposs√≠vel perder transa√ß√£o em sistemas regulados).

---

Se quiser, posso gerar uma **planilha Excel autom√°tica** com todas essas etapas ‚Äî com colunas de ‚ÄúStatus‚Äù, ‚ÄúRespons√°vel‚Äù, ‚ÄúData de Execu√ß√£o‚Äù e ‚ÄúObserva√ß√µes‚Äù ‚Äî pronta para uso em auditorias ou squads DevOps.
Quer que eu monte esse arquivo?

===================================

# ‚úÖ Plano de Testes de Performance & Resili√™ncia ‚Äî Pipeline JSON + Mensageria + DB Relacional

## 0) Escopo do sistema sob teste (SUT)

- **Entrada:** arquivos `.json` (at√© 100.000 registros/arquivo).
- **Processamento:** pipeline sequenciado; orquestrador define **ordem** e **paralelismo**; todos os est√°gios comunicam via **mensageria** (pub/sub, filas, DLQ).
- **Sa√≠da:** **1 registro por linha** em banco relacional (INSERT/UPSERT).
- **Garantias desejadas:** alta vaz√£o, baixa lat√™ncia p95/p99, **idempot√™ncia** (sem efeito colateral em reprocesso), **reprocessamento seguro**, **zero perda** e **zero duplica√ß√£o** (ou duplica√ß√£o detectada e saneada).

---

## 1) Prepara√ß√£o e premissas

- **Ambiente isolado** (staging/performance) espelhando produ√ß√£o (mesmas vers√µes de servi√ßos, schemas, √≠ndices, limites).
- **Dados sint√©ticos controlados**: gerador que cria arquivos com padr√µes realistas (payloads v√°lidos/ inv√°lidos, chaves repetidas, ordem variada).
- **Observabilidade ligada**: m√©tricas e logs por est√°gio (lat√™ncia, throughput, lag de filas, taxas de retry, DLQ, commit/rollback DB).
- **Controle de cache e autoescalonamento**: documentar pol√≠ticas de HPA/ASG e limites de conex√µes com o DB.
- **Flag de idempot√™ncia** ativa em todos os handlers que possam reprocessar mensagens/registros.

**Pontos de aten√ß√£o**

- N√£o testar com caches frios num ciclo e quentes em outro sem registrar isso.
- Garantir `unique key`/`upsert` no DB para deduplica√ß√£o (ver **Se√ß√£o 5.3**).

---

## 2) Objetivos e SLAs sugeridos

> Adapte n√∫meros ao seu neg√≥cio‚Äîo formato √© o que importa.

- **Throughput**: ‚â• _X_ mil registros/min (pico ‚â• _Y_ mil).
- **Lat√™ncia fim-a-fim p95** (receber arquivo ‚Üí persistir todas as linhas): ‚â§ _N_ min p95; ‚â§ _M_ min p99.
- **Erros irrecuper√°veis**: ‚â§ 0,1% (com roteamento para DLQ e _playback_).
- **Perda de dados**: 0.
- **Duplica√ß√£o**: 0 vis√≠vel (ou ‚â§ _DPPM_ com auto-saneamento).
- **MTTR** ap√≥s falha de n√≥/servi√ßo: ‚â§ 5 min at√© retomada de processamento.
- **Reprocesso**: idempotente (sem linhas extras nem corrup√ß√£o).

---

## 3) Modelos de carga (workloads)

1. **Nominal (steady load)**

   - 10 arquivos √ó 100k cada (1 milh√£o de registros); chegada suave (ex.: 1 arquivo/3 min).

2. **Pico (spike)**

   - 10 arquivos simult√¢neos √ó 100k cada (chegada em 30s).

3. **Endurance (soak)**

   - 6‚Äì12 horas cont√≠nuas, 1‚Äì2 arquivos/min (volumetria total 30‚Äì100 milh√µes).

4. **Explos√£o de pequenos**

   - 2.000 arquivos √ó 2k registros (testa overhead de orquestra√ß√£o/escala).

5. **Misto com falhas**

   - Mistura nominal + inje√ß√£o de falhas (rede, n√≥, lat√™ncia, throttle do DB) a cada _X_ minutos.

---

## 4) Paralelismo e orquestra√ß√£o

### 4.1 Testes de paralelismo do pipeline

- **Objetivo:** validar que _N_ workers escalam quase linearmente at√© o ponto de satura√ß√£o (CPU, DB, rede ou broker).
- **Cen√°rios:**

  - **Escada de paralelismo:** N={1, 2, 4, 8, 16, 32}. Me√ßa throughput e p95 a cada degrau.
  - **Limited by DB:** max connections/transactions deliberadamente baixos para medir fila interna e backpressure.
  - **Limited by broker:** reduza prefetch/parti√ß√µes para for√ßar gargalo na mensageria.
  - **Bound por IO:** aumente tamanho de payload/serializa√ß√£o para ver impacto na CPU/GC.

**M√©tricas alvo**

- Throughput vs N de workers (curva de ganho).
- **Utiliza√ß√£o DB** (TPS, lock waits, I/O), **lag de fila**, **taxa de reentrega**.
- **Ponto de satura√ß√£o**: 1¬∫ componente a 80‚Äì90%.

### 4.2 Ordem e consist√™ncia

- Se a **ordem por arquivo** for requisito, valide:

  - Particionamento por _fileId_ (garantir consumo ordenado por parti√ß√£o ou _sequence key_).
  - Processamento **intra-arquivo**: chunks paralelos mas commit ordenado? Documentar regra e testar.

---

## 5) Integridade de dados: perda, duplica√ß√£o, idempot√™ncia

### 5.1 Perda de dados

- **Como medir**

  - `count(input_registros)` vs `count(db_linhas)` + `count(DLQ)` + `count(em processamento)` ‚Üí **tem que fechar 100%**.
  - Checksum por arquivo: `sum(hash(businessKey))` comparado entre entrada e sa√≠da (descontando inv√°lidos que foram para DLQ).

- **Casos de teste**

  1. Interromper consumidor no meio do arquivo; religar e verificar reconcilia√ß√£o = 0 perda.
  2. Falha de rede entre est√°gio e DB com retry ‚Üí nenhuma linha perdida, sem duplicar.
  3. Queda do orquestrador com mensagens em voo ‚Üí ap√≥s _re-delivery_, reconcilia√ß√£o fecha.

### 5.2 Duplica√ß√µes

- **Fontes comuns**

  - Entrega **at-least-once** do broker, _timeouts_ de commit, _retry_ ap√≥s _ACK_ tardio, reprocesso de arquivo.

- **Estrat√©gias de conten√ß√£o**

  - **Idempotency Key** por registro (ex.: `businessKey` ou `hash(payload can√¥nico)`).
  - **UPSERT** (chave √∫nica no DB) em vez de `INSERT` simples.
  - **Tabelas de dedupe** com TTL curto para grava√ß√µes recentes.

- **Casos de teste**

  1. Reenvio do **mesmo arquivo** (mesmo `fileId`) ‚Üí 0 novas linhas no DB.
  2. Reenvio de **arquivo id√™ntico com novo `fileId`** ‚Üí se neg√≥cio exige dedupe global, 0 novas linhas; caso contr√°rio, duplica√ß√£o esperada e medida.
  3. Mensagem duplicada pelo broker (for√ßada via script) ‚Üí 0 linhas extras (UPSERT deve segurar).
  4. Conflito competitivo (2 workers tentam gravar mesma chave) ‚Üí **viola√ß√£o √∫nica** no DB deve ser tratada com retry controlado (e n√£o travar fila).

### 5.3 Idempot√™ncia (reprocesso seguro)

- **Requisitos**

  - Toda opera√ß√£o de escrita deve ser **idempotente**: m√∫ltiplas tentativas produzem o **mesmo** estado final.
  - **Side effects** (auditoria, eventos derivados) tamb√©m precisam de idempot√™ncia (ex.: outbox transacional).

- **Casos de teste**

  1. _Replay_ do lote inteiro (mesmo `fileId`) 3 vezes ‚Üí contagem final no DB n√£o muda.
  2. _Replay_ parcial (do registro _k_ ao _k+n_) ‚Üí estado final consistente.
  3. Conex√£o cai ap√≥s `INSERT` mas antes do ACK ‚Üí servi√ßo reenvia; DB segura via **unique key**.

**SQL de apoio (exemplo gen√©rico)**

```sql
-- duplicatas por business_key
SELECT business_key, COUNT(*)
FROM tabela_saida
GROUP BY business_key HAVING COUNT(*) > 1;

-- confer√™ncia por arquivo
SELECT file_id, COUNT(*)
FROM tabela_saida
GROUP BY file_id;

-- diferen√ßa entre input esperado e output realizado (usar staging_input para refer√™ncia)
SELECT i.file_id, (i.qtd - o.qtd) AS faltantes
FROM inputs_esperados i
LEFT JOIN (
  SELECT file_id, COUNT(*) AS qtd FROM tabela_saida GROUP BY file_id
) o USING (file_id);
```

---

## 6) Testes de resili√™ncia (Chaos & fault injection)

### 6.1 Falhas de infraestrutura

- **Queda de n√≥/worker**: matar 10‚Äì30% dos pods no pico; verificar MTTR, auto-rebalance do broker e **aus√™ncia de perda/duplica√ß√£o**.
- **Parti√ß√£o de rede** entre est√°gio e DB por 2‚Äì5 min: medir backlog, retries, _throttling_ e recupera√ß√£o.
- **Degrada√ß√£o do DB** (lat√™ncia +200%, conex√µes m√°x. atingidas): confirmar backpressure no pipeline (sem _timeout storm_).

### 6.2 Falhas funcionais

- **Poison messages**: registros inv√°lidos que sempre falham ‚Üí roteamento para **DLQ** com metadados (fileId, offset, erro).
- **Falhas intermitentes** (ex.: 5xx aleat√≥rios em servi√ßo de enriquecimento): pol√≠tica de retry exponencial + jitter; **sem efeito de tempestade**.

### 6.3 Recupera√ß√£o e reprocesso

- Procedimento **runbook**:

  - (1) Identificar causa, (2) drenar fila ou isolar parti√ß√£o, (3) corrigir, (4) **replay** seguro (por `fileId` ou _offset range_), (5) reconcilia√ß√£o SQL, (6) ‚Äúgo/ no-go‚Äù para liberar DLQ.

**M√©tricas de resili√™ncia**

- **MTTR**, **tamanho do backlog** vs tempo, **taxa de retry**, **DLQ inflow/outflow**, **tempo para normalizar p95** ap√≥s falha.

---

## 7) Performance end-to-end

### 7.1 Tipos de teste

- **Load**: capacidade nominal com _thresholds_ de aprova√ß√£o (p95, throughput).
- **Stress**: achar o colapso controlado (onde filas explodem, DB satura, timeouts).
- **Spike**: 10 arquivos gigantes ao mesmo tempo ‚Üí medir _autoscaling lag_.
- **Endurance**: 6‚Äì12h para detectar vazamentos de mem√≥ria, GC long pause, crescimento de conex√µes.

### 7.2 M√©tricas obrigat√≥rias

| Categoria  | M√©trica                                          | Como analisar                                          |
| ---------- | ------------------------------------------------ | ------------------------------------------------------ |
| Lat√™ncia   | p50/p95/p99 por est√°gio e fim-a-fim por arquivo  | Quedas de cauda longa indicam conten√ß√£o (DB, GC, lock) |
| Throughput | registros/s e arquivos/h                         | Curva vs paralelismo; identificar ponto de satura√ß√£o   |
| Broker     | lag por fila/t√≥pico/parti√ß√£o, reentregas         | Lag crescente = gargalo downstream                     |
| DB         | TPS, locks, filas de espera, I/O, √≠ndices usados | Se p95 aumenta com DB est√°vel ‚Üí gargalo √© antes        |
| Erros      | % 4xx/5xx por est√°gio, DLQ rate                  | 4xx: dados; 5xx: sistema                               |
| Custo      | $ por 1M registros                               | Otimizar autoescalonamento e batch size                |

---

## 8) Qualidade de persist√™ncia (relacional)

### 8.1 Chaves e √≠ndices

- **Unique** sobre `business_key` (ou `fileId+recordId`), suportando **UPSERT** (ex.: `INSERT ... ON CONFLICT DO UPDATE`).
- √çndices em colunas de consulta/report (datas, status, fileId).
- Tuning de **batch size** de escrita (ex.: 500‚Äì2.000 linhas por transa√ß√£o) para equilibrar TPS/lock/redo log.

### 8.2 Transa√ß√µes

- **Atomicidade por bloco**: em falha, _rollback_ limpa parcial.
- **Outbox transacional** (se publicar eventos ap√≥s persistir).
- **Deadlocks**: simular concorr√™ncia em mesma `business_key` e validar retries com _backoff_.

---

## 9) Cen√°rios de teste detalhados (passo a passo)

### C1 ‚Äî Pipeline nominal (100k)

- **Dado** 1 arquivo com 100k registros v√°lidos.
- **Quando** processado com N=8 workers.
- **Ent√£o** p95 ‚â§ SLA, `count(DB)=100k`, `DLQ=0`, duplica√ß√µes=0.

### C2 ‚Äî Parallel scale-up

- Mesmos dados, repetir com N={1,2,4,8,16,32}.
- **Esperado**: ganho quase linear at√© saturar; registrar **componente limitante**.

### C3 ‚Äî Pico simult√¢neo (10√ó100k)

- **Quando** chega 1M de registros quase ao mesmo tempo.
- **Ent√£o** autoscaling aciona, lag no broker volta ao normal ‚â§ _T_ min; sem perda ou duplica√ß√£o.

### C4 ‚Äî Reenvio do mesmo arquivo (idempot√™ncia)

- **Quando** o mesmo arquivo (mesmo `fileId`) √© reprocessado 3 vezes.
- **Ent√£o** `count(DB)` n√£o aumenta; delta=0.

### C5 ‚Äî Reenvio de arquivo id√™ntico com _novo_ `fileId`

- **Se** dedupe global for requisito: delta=0.
- **Se n√£o for**: delta=+100k (com rastreabilidade por `fileId`).

### C6 ‚Äî Consumer crash

- **Quando** 30% dos consumidores caem no meio do processamento.
- **Ent√£o** MTTR ‚â§ 5 min; backlog estabiliza; reconcilia√ß√£o fecha 100%.

### C7 ‚Äî DB lento + limite de conex√µes

- **Quando** adiciona +200% de lat√™ncia no DB e reduz conex√µes m√°x.
- **Ent√£o** pipeline faz backpressure, sem tempestade de timeouts; sem perda/dup.

### C8 ‚Äî Poison messages

- **Dado** 2% registros inv√°lidos.
- **Quando** processados.
- **Ent√£o** v√£o para DLQ com motivo; `DB` s√≥ cont√©m v√°lidos; relat√≥rio lista amostras e causas.

### C9 ‚Äî Falha de rede intermitente (broker‚Üîworkers)

- **Quando** existirem quedas de 30‚Äì60s a cada 5 min.
- **Ent√£o** retry com _exponential backoff_; sem efeito cascata; sem perda de ACK.

### C10 ‚Äî Reprocesso parcial por intervalo

- **Quando** reprocessar do offset 50k‚Äì70k do arquivo A.
- **Ent√£o** estado final consistente (sem duplicar; sem buracos).

### C11 ‚Äî Conflito de escrita (race)

- **Dado** 2 workers recebem a mesma `business_key`.
- **Ent√£o** 1 grava, o outro recebe erro de unique e faz retry/backoff ‚Üí sem duplica√ß√£o.

### C12 ‚Äî Endurance 12h

- **Quando** rodar carga cont√≠nua.
- **Ent√£o** sem vazamento de mem√≥ria, sem crescimento infinito de conex√µes, p95 est√°vel.

---

## 10) T√°ticas de instrumenta√ß√£o & valida√ß√£o

### 10.1 M√©tricas m√≠nimas por est√°gio

- `records_in/records_out`, `latency_p95/p99`, `retries`, `dead_letter_count`, `consumer_lag`, `db_tps`, `db_errors`, `gc_pause_ms`.

### 10.2 Logs e tracing

- **Correla√ß√£o** por `traceId`/`fileId`/`recordId`.
- **Sampling din√¢mico**: aumentar amostra em erro.
- **Eventos de auditoria**: `received`, `validated`, `persisted`, `ack`.

### 10.3 Reconciliation automatizado

- Job que compara entrada √ó sa√≠da √ó DLQ ap√≥s cada rodada e gera **relat√≥rio de integridade**:

  - Perdas = 0
  - Duplica√ß√µes = 0 (ou lista controlada com _auto-fix_)
  - Registros inv√°lidos catalogados por categoria de erro.

---

## 11) Crit√©rios de aprova√ß√£o (go/no-go)

- Atingir SLAs de **throughput** e **lat√™ncia** nas cargas **nominal** e **pico**.
- **Perda** = 0; **duplica√ß√£o** = 0 (ou ‚â§ alvo com rotina de saneamento automatizada).
- **MTTR** dentro do limite; **DLQ** com _playbook_ validado.
- **Idempot√™ncia** comprovada nos cen√°rios C4/C10.
- **Endurance** sem degrada√ß√£o progressiva.

---

## 12) Relat√≥rio final (template)

1. **Resumo executivo**: atingiu SLAs? riscos residuais?
2. **Ambiente**: vers√µes, sizing, configs (broker, DB, √≠ndices, HPA).
3. **Carga**: arquivos, volumetria, formato, distribui√ß√£o temporal.
4. **Resultados**: tabelas de p50/p95/p99, throughput, lag, DB TPS, retries, DLQ.
5. **Integridade**: reconcilia√ß√£o, perdas, duplica√ß√µes, inv√°lidos.
6. **Resili√™ncia**: MTTR, comportamento sob falhas, a√ß√µes autom√°ticas.
7. **Bottlenecks & root causes**: onde saturou, por qu√™, gr√°ficos.
8. **A√ß√µes recomendadas**: tuning, refatora√ß√µes, √≠ndices, pol√≠ticas de retry/backoff, batch size, limites de conex√£o, dedupe.
9. **Pr√≥ximos passos**: re-testes ap√≥s corre√ß√µes, metas elevadas, ajuste de custo.

---

## 13) Dicas pr√°ticas (evitam dor de cabe√ßa)

- **Defina a idempotency key oficialmente** (ex.: `business_key`; se n√£o houver, `hash(normalized_payload)`), e **garanta UPSERT**.
- **Prefetch/Batch**: teste `prefetch` baixo vs alto e `batch size` de escrita no DB (500‚Äì2000) ‚Äî quase sempre d√° ganhos grandes.
- **Particionamento de fila por `fileId`** se precisar de **ordem dentro do arquivo**.
- **DLQ com metadados ricos** (erro, est√°gio, tentativa, offsets) e **playback por janela**.
- **Alarmes** por **lag**, **retries** e **p95**; alerta por **‚Äútaxa de duplica√ß√£o > 0‚Äù**.
- **Scripts SQL de reconcilia√ß√£o** incorporados ao pipeline de valida√ß√£o p√≥s-lote.

---

### Quer o ‚Äúpacote operacional‚Äù?

Eu posso j√° te entregar uma **planilha de execu√ß√£o** (CSV/Excel) com:

- Caso de teste, Objetivo, Dados de entrada, Passos, M√©tricas a coletar, Crit√©rio de aceite, Resultado, A√ß√£o corretiva.
- E um **script SQL base** de reconcilia√ß√£o (par√¢metros por `fileId`).

Se quiser, digo ‚Äúsim‚Äù e eu j√° gero os arquivos agora.
